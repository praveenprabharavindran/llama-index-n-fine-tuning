{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyM3tjWlgSdUxG4Sg11qyymP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenprabharavindran/llama-index-n-fine-tuning/blob/main/llama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!add-apt-repository ppa:deadsnakes/ppa\n",
        "!apt-get update\n",
        "!apt-get install python3.10\n",
        "!python3.10 --version\n",
        "\n"
      ],
      "metadata": {
        "id": "yYFTdtrbg05v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index\n",
        "!pip install openai\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "id": "NATQ3XClzafO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lUenBh8txWW"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\n",
        "from llama_index import GPTSimpleVectorIndex, Document, SimpleDirectoryReader, LLMPredictor, ServiceContext, PromptHelper\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import OpenAI\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = '<Enter api Key here'"
      ],
      "metadata": {
        "id": "OojJBRI63cs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text from target site\n",
        "url = 'https://yaml.org/spec/1.2.2/'\n",
        "response = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find the <div> tag with class \"content\"\n",
        "content_div = soup.find('div', {'class': 'container'})\n",
        "\n",
        "if content_div:\n",
        "    # Find all the <p> tags within the content_div and append their text to the 'text' variable\n",
        "    text = ''\n",
        "    for p in content_div.find_all('p'):\n",
        "        text += p.text + '\\n'\n",
        "else:\n",
        "    print('Content not found on the page')\n"
      ],
      "metadata": {
        "id": "7Qn3UucaZ-Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_index_davinci_003(documents):\n",
        "    max_input_size = 4096\n",
        "    num_outputs = 2048\n",
        "    max_chunk_overlap = 20\n",
        "    chunk_size_limit = 600\n",
        "\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        "\n",
        "    llm_predictor_gpt = LLMPredictor(llm=OpenAI(temperature=0.7, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
        "\n",
        "      # index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor_gpt, prompt_helper=prompt_helper)\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(\n",
        "        llm_predictor=llm_predictor_gpt, prompt_helper=prompt_helper\n",
        "    )\n",
        "\n",
        "    index = GPTSimpleVectorIndex.from_documents(documents,service_context=service_context)\n",
        "\n",
        "    # index.save_to_disk('index.json')\n",
        "\n",
        "    return index"
      ],
      "metadata": {
        "id": "DA_c8bPGzA_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_index_gpt_35_turbo(documents):\n",
        "    max_input_size = 4096\n",
        "    num_outputs = 512\n",
        "    max_chunk_overlap = 20\n",
        "    chunk_size_limit = 600\n",
        "\n",
        "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
        "\n",
        "    llm_predictor_gpt = LLMPredictor(llm=ChatOpenAI(temperature=0.7, model_name=\"gpt-3.5-turbo\", max_tokens=num_outputs))\n",
        "\n",
        "      # index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor_gpt, prompt_helper=prompt_helper)\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(\n",
        "        llm_predictor=llm_predictor_gpt, prompt_helper=prompt_helper\n",
        "    )\n",
        "\n",
        "    index = GPTSimpleVectorIndex.from_documents(documents,service_context=service_context)\n",
        "\n",
        "    # index.save_to_disk('index.json')\n",
        "\n",
        "    return index"
      ],
      "metadata": {
        "id": "p-PgxMF05J2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to open ai and build index\n",
        "text_list = [text]\n",
        "documents = [Document(t) for t in text_list]\n",
        "\n",
        "# build index\n",
        "#index = construct_index_davinci_003(documents)\n",
        "index = construct_index_gpt_35_turbo(documents)"
      ],
      "metadata": {
        "id": "Q_38ZBA8Pq2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Querying the index\n",
        "#response = index.query(\"Briefly summarize the history of yaml\")\n",
        "#response = index.query(\"What are explicit tags in yaml\")\n",
        "response = index.query(\"Suggest an outline for a 20 minute presentation on yaml based on the document\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Sc8NnE8bRtEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0J1iWW1QotT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}